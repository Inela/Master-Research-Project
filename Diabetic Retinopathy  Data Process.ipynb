{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create train , validation and test data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "original_dataset_dir = 'C:\\\\Ryerson Courses\\\\MRP Project\\\\Kaggle Diabetic Retinopathy data\\\\train data\\\\train'\n",
    "base_dir = 'C:\\\\Ryerson Courses\\\\MRP Project\\\\Kaggle Diabetic Retinopathy data\\\\train data\\\\train_small'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "train_class0_dir = os.path.join(train_dir, 'class_0')\n",
    "os.mkdir(train_class0_dir)\n",
    "train_class1_dir = os.path.join(train_dir, 'class_1')\n",
    "os.mkdir(train_class1_dir)\n",
    "train_class2_dir = os.path.join(train_dir, 'class_2')\n",
    "os.mkdir(train_class2_dir)\n",
    "train_class3_dir = os.path.join(train_dir, 'class_3')\n",
    "os.mkdir(train_class3_dir)\n",
    "train_class4_dir = os.path.join(train_dir, 'class_4')\n",
    "os.mkdir(train_class4_dir)\n",
    "\n",
    "\n",
    "\n",
    "validation_class0_dir = os.path.join(validation_dir, 'class_0')\n",
    "os.mkdir(validation_class0_dir)\n",
    "validation_class1_dir = os.path.join(validation_dir, 'class_1')\n",
    "os.mkdir(validation_class1_dir)\n",
    "validation_class2_dir = os.path.join(validation_dir, 'class_2')\n",
    "os.mkdir(validation_class2_dir)\n",
    "validation_class3_dir = os.path.join(validation_dir, 'class_3')\n",
    "os.mkdir(validation_class3_dir)\n",
    "validation_class4_dir = os.path.join(validation_dir, 'class_4')\n",
    "os.mkdir(validation_class4_dir)\n",
    "\n",
    "\n",
    "test_class0_dir = os.path.join(test_dir, 'class_0')\n",
    "os.mkdir(test_class0_dir)\n",
    "test_class1_dir = os.path.join(test_dir, 'class_1')\n",
    "os.mkdir(test_class1_dir)\n",
    "test_class2_dir = os.path.join(test_dir, 'class_2')\n",
    "os.mkdir(test_class2_dir)\n",
    "test_class3_dir = os.path.join(test_dir, 'class_3')\n",
    "os.mkdir(test_class3_dir)\n",
    "test_class4_dir = os.path.join(test_dir, 'class_4')\n",
    "os.mkdir(test_class4_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabel = pd.read_csv('C:\\\\Ryerson Courses\\\\MRP Project\\\\Kaggle Diabetic Retinopathy data\\\\trainLabels.csv\\\\trainLabels.csv')\n",
    "trainLabel\n",
    "trainLabel['image'] ,trainLabel['level']\n",
    "\n",
    "trainLabel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "fnames_0 = []\n",
    "fnames_1 = []\n",
    "fnames_2 = []\n",
    "fnames_3 = []\n",
    "fnames_4 = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['level']   == 0 :\n",
    "      fnames_0.append(row['image'])\n",
    " \n",
    "    if row['level']   == 1 :\n",
    "       fnames_1.append(row['image'])\n",
    " \n",
    "    if row['level']   == 2 :\n",
    "       fnames_2.append(row['image'])\n",
    " \n",
    "    if row['level']   == 3 :\n",
    "       fnames_3.append(row['image'])\n",
    " \n",
    "    if row['level']   == 4 :\n",
    "       fnames_4.append(row['image'])\n",
    " \n",
    " \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25810 2443 5292 873 708\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(  len(fnames_0) , len(fnames_1 ) ,  len(fnames_2 ) ,  len(fnames_3 ) ,  len(fnames_4 )   )  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy files from the original folder into train, validation and test data folder per each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create class_0 train , validation , test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"  Class_0 train , validation , test set \"\"\"\n",
    "\n",
    "\"\"\" All Smaples from Class_0 \"\"\"\n",
    "sample_0 = 0.1 * len(fnames_0)\n",
    "\n",
    "train_num = int(0.5 * sample_0 )  \n",
    "val_num = int(0.25 * sample_0 )  \n",
    "test_num = int(0.25 *  sample_0 ) \n",
    " \n",
    "train_end = train_num \n",
    "val_start =train_end   + 1 \n",
    "val_end =val_start + val_num\n",
    "test_start = val_end + 1 \n",
    "test_end = test_start + test_num \n",
    "\n",
    "\"\"\" Start copy from original_dir to train , validation , test dir for Class_0  \"\"\"\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_0[0:train_end]]\n",
    "for fname in fnames:\n",
    "#for fname in fnames_0[0:train_end]:\n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(train_class0_dir, fname)\n",
    " shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_0[val_start :val_end]]\n",
    "for fname in fnames:\n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(validation_class0_dir, fname)\n",
    " shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_0[test_start :test_end]]\n",
    "for fname in fnames: \n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(test_class0_dir, fname)\n",
    " shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create class_1 train , validation , test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"  Class_1 train , validation , test set \"\"\"\n",
    "\n",
    "\"\"\" All Smaples from Class_1 \"\"\"\n",
    "sample_1 = 0.1 * len(fnames_1)\n",
    "\n",
    "train_num = int(0.5 * sample_1 )  \n",
    "val_num = int(0.25 * sample_1 )  \n",
    "test_num = int(0.25 *  sample_1 ) \n",
    " \n",
    "train_end = train_num \n",
    "val_start =train_end   + 1 \n",
    "val_end =val_start + val_num\n",
    "test_start = val_end + 1 \n",
    "test_end = test_start + test_num \n",
    "\n",
    "\"\"\" Start copy from original_dir to train , validation , test dir for Class_1  \"\"\"\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_1[0:train_end]]\n",
    "for fname in fnames:\n",
    "#for fname in fnames_1[0:train_end]:\n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(train_class1_dir, fname)\n",
    " shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_1[val_start :val_end]]\n",
    "for fname in fnames:\n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(validation_class1_dir, fname)\n",
    " shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_1[test_start :test_end]]\n",
    "for fname in fnames: \n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(test_class1_dir, fname)\n",
    " shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Create class_2 train , validation , test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"  Class_2 train , validation , test set \"\"\"\n",
    "\n",
    "\"\"\" All Smaples from Class_2 \"\"\"\n",
    "sample_2 = 0.1 * len(fnames_2)\n",
    "\n",
    "train_num = int(0.5 * sample_2 )  \n",
    "val_num = int(0.25 * sample_2 )  \n",
    "test_num = int(0.25 *  sample_2 ) \n",
    " \n",
    "train_end = train_num \n",
    "val_start =train_end   + 1 \n",
    "val_end =val_start + val_num\n",
    "test_start = val_end + 1 \n",
    "test_end = test_start + test_num \n",
    "\n",
    "\"\"\" Start copy from original_dir to train , validation , test dir for Class_2  \"\"\"\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_2[0:train_end]]\n",
    "for fname in fnames:\n",
    "#for fname in fnames_2[0:train_end]:\n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(train_class2_dir, fname)\n",
    " shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_2[val_start :val_end]]\n",
    "for fname in fnames:\n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(validation_class2_dir, fname)\n",
    " shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_2[test_start :test_end]]\n",
    "for fname in fnames: \n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(test_class2_dir, fname)\n",
    " shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create class_3 train , validation , test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"  Class_3 train , validation , test set \"\"\"\n",
    "\n",
    "\"\"\" All Smaples from Class_3 \"\"\"\n",
    "sample_3 = 0.1 * len(fnames_3)\n",
    "\n",
    "train_num = int(0.5 * sample_3 )  \n",
    "val_num = int(0.25 * sample_3 )  \n",
    "test_num = int(0.25 *  sample_3 ) \n",
    " \n",
    "train_end = train_num \n",
    "val_start =train_end   + 1 \n",
    "val_end =val_start + val_num\n",
    "test_start = val_end + 1 \n",
    "test_end = test_start + test_num \n",
    "\n",
    "\"\"\" Start copy from original_dir to train , validation , test dir for Class_3  \"\"\"\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_3[0:train_end]]\n",
    "for fname in fnames:\n",
    "#for fname in fnames_3[0:train_end]:\n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(train_class3_dir, fname)\n",
    " shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_3[val_start :val_end]]\n",
    "for fname in fnames:\n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(validation_class3_dir, fname)\n",
    " shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_3[test_start :test_end]]\n",
    "for fname in fnames: \n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(test_class3_dir, fname)\n",
    " shutil.copyfile(src, dst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Create class_4 train , validation , test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"  Class_4 train , validation , test set \"\"\"\n",
    "\n",
    "\"\"\" All Smaples from Class_4 \"\"\"\n",
    "sample_4 = 0.1 * len(fnames_4)\n",
    "\n",
    "train_num = int(0.5 * sample_4 )  \n",
    "val_num = int(0.25 * sample_4 )  \n",
    "test_num = int(0.25 *  sample_4 ) \n",
    " \n",
    "train_end = train_num \n",
    "val_start =train_end   + 1 \n",
    "val_end =val_start + val_num\n",
    "test_start = val_end + 1 \n",
    "test_end = test_start + test_num \n",
    "\n",
    "\"\"\" Start copy from original_dir to train , validation , test dir for Class_4  \"\"\"\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_4[0:train_end]]\n",
    "for fname in fnames:\n",
    "#for fname in fnames_4[0:train_end]:\n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(train_class4_dir, fname)\n",
    " shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_4[val_start :val_end]]\n",
    "for fname in fnames:\n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(validation_class4_dir, fname)\n",
    " shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['{}.jpeg'.format(name) for name in fnames_4[test_start :test_end]]\n",
    "for fname in fnames: \n",
    " src = os.path.join(original_dataset_dir, fname)\n",
    " dst = os.path.join(test_class4_dir, fname)\n",
    " shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training Class_0 images: 1290\n",
      "total training Class_1 images: 122\n",
      "total training Class_2 images: 264\n",
      "total training Class_3 images: 43\n",
      "total training Class_4 images: 35\n",
      "total validation Class_0 images: 645\n",
      "total validation Class_1 images: 61\n",
      "total validation Class_2 images: 132\n",
      "total validation Class_3 images: 21\n",
      "total validation Class_4 images: 17\n",
      "total test Class_0 images: 645\n",
      "total test Class_1 images: 61\n",
      "total test Class_2 images: 132\n",
      "total test Class_3 images: 21\n",
      "total test Class_4 images: 17\n"
     ]
    }
   ],
   "source": [
    "print('total training Class_0 images:', len(os.listdir(train_class0_dir)))\n",
    "print('total training Class_1 images:', len(os.listdir(train_class1_dir)))\n",
    "print('total training Class_2 images:', len(os.listdir(train_class2_dir)))\n",
    "print('total training Class_3 images:', len(os.listdir(train_class3_dir)))\n",
    "print('total training Class_4 images:', len(os.listdir(train_class4_dir)))\n",
    "\n",
    "print('total validation Class_0 images:', len(os.listdir(validation_class0_dir)))\n",
    "print('total validation Class_1 images:', len(os.listdir(validation_class1_dir)))\n",
    "print('total validation Class_2 images:', len(os.listdir(validation_class2_dir)))\n",
    "print('total validation Class_3 images:', len(os.listdir(validation_class3_dir)))\n",
    "print('total validation Class_4 images:', len(os.listdir(validation_class4_dir)))\n",
    "\n",
    "print('total test Class_0 images:', len(os.listdir(test_class0_dir)))\n",
    "print('total test Class_1 images:', len(os.listdir(test_class1_dir)))\n",
    "print('total test Class_2 images:', len(os.listdir(test_class2_dir)))\n",
    "print('total test Class_3 images:', len(os.listdir(test_class3_dir)))\n",
    "print('total test Class_4 images:', len(os.listdir(test_class4_dir)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
